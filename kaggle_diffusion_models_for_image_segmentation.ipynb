{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Models for Image Segmentation\n",
    "\n",
    "https://www.kaggle.com/code/user164919/diffusion-models-for-image-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from monai import transforms\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, load_decathlon_datalist, CacheDataset\n",
    "from monai.utils import set_determinism\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import logger\n",
    "\n",
    "from generative.inferers import DiffusionInferer\n",
    "from generative.networks.nets.diffusion_model_unet import DiffusionModelUNet\n",
    "from generative.networks.schedulers.ddpm import DDPMScheduler\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "print_config()\n",
    "\n",
    "_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "LOG_PATH = f\"training_log_{_time}.txt\"\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    with open(LOG_PATH, 'w') as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s', handlers=[\n",
    "    logging.FileHandler(LOG_PATH),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../../../../mnt/sda/suhohan/hutu-80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(2650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_descr_json = {\n",
    "    \"description\": \"Hutu-80 dataset\",\n",
    "    \"name\": \"Hutu-80 Dataset\",\n",
    "    \"test\": [],\n",
    "    \"training\": [],\n",
    "    \"validation\": []\n",
    "}\n",
    "\n",
    "all_images = glob(os.path.join(root_dir, 'images', '*.png'))\n",
    "logger.info(f'Found {len(all_images)} images')\n",
    "\n",
    "train_images, test_images = train_test_split(all_images, test_size=0.2, random_state=2650)\n",
    "logger.info(f'Train images: {len(train_images)}, Test images: {len(test_images)}')\n",
    "\n",
    "dataset_descr_json['training'] = []\n",
    "for image in tqdm(train_images, desc='Processing training images'):\n",
    "    dataset_descr_json['training'].append({\n",
    "        'image': image,\n",
    "        'label': image.replace('images', 'masks')\n",
    "    })\n",
    "\n",
    "dataset_descr_json[\"validation\"] = []\n",
    "for image in tqdm(test_images, desc='Processing validation images'):\n",
    "    dataset_descr_json['validation'].append({\n",
    "        'image': image,\n",
    "        'label': image.replace('images', 'masks')\n",
    "    })\n",
    "\n",
    "logger.info(f\"dataset_descr_json[training]: {len(dataset_descr_json['training'])}\")\n",
    "logger.info(f\"dataset_descr_json[validation]: {len(dataset_descr_json['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "split_JSON = \"./dataset_0.json\"\n",
    "with open(split_JSON, 'w') as fp:\n",
    "    json.dump(dataset_descr_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        # 이미지와 레이블 데이터를 메모리에 로드\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # 채널을 첫 번째 차원으로 변환\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        # 레이블 데이터를 이진화\n",
    "        transforms.Lambdad(keys=[\"label\"], func=lambda x: np.where(\n",
    "            x[0, :, :].unsqueeze(0) > 127, 1, 0), overwrite=True),\n",
    "        # 데이터를 PyTorch 텐서 형식으로 변환\n",
    "        transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        # 이미지 크기 조정\n",
    "        transforms.Resized(keys=[\"image\", \"label\"], spatial_size=(512, 512), mode=[\"bilinear\", \"nearest\"]),\n",
    "        # 이미지 강도를 0에서 1 사이로 스케일링\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower=0, upper=99.5, b_min=0, b_max=1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = load_decathlon_datalist(split_JSON, True, 'training')\n",
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Length of training data: {len(train_ds)}\")\n",
    "logger.info(f'Train image shape {train_ds[0][\"image\"].shape}')\n",
    "logger.info(f'Train label shape {train_ds[0][\"label\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=True, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = load_decathlon_datalist(split_JSON, True, 'validation')\n",
    "val_ds = CacheDataset(data=val_files, transform=train_transforms, cache_rate=1.0, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Length of training data: {len(val_ds)}\")\n",
    "logger.info(f'Validation image shape {val_ds[0][\"image\"].shape}')\n",
    "logger.info(f'Validation label shape {val_ds[0][\"label\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModelUNet(spatial_dims=2, in_channels=4, out_channels=1, num_channels=(64, 64, 64), attention_levels=(\n",
    "    False, False, True), num_res_blocks=1, num_head_channels=64, with_conditioning=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "n_timesteps = 10\n",
    "val_interval = 5\n",
    "epoch_loss_list = []\n",
    "val_epoch_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler(num_train_timesteps=n_timesteps)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)\n",
    "inferer = DiffusionInferer(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "total_start = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for step, data in enumerate(train_loader):\n",
    "        images = data[\"image\"].to(device)\n",
    "        seg = data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        timesteps = torch.randint(0, n_timesteps, (len(images),)).to(device)\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            noise = torch.randn_like(seg).to(device)\n",
    "            noisy_seg = scheduler.add_noise(original_samples=seg, noise=noise, timesteps=timesteps)\n",
    "            combined = torch.cat((images, noisy_seg), dim=1)\n",
    "            img_array = noisy_seg[0, 0].detach().cpu().numpy()\n",
    "            if epoch == 0:\n",
    "                plt.imsave(f'results/image_epoch{epoch}_step{step}.png',\n",
    "\n",
    "                           images[0, 0].detach().cpu().numpy(), cmap='gray')\n",
    "                plt.imsave(f'results/noisy_seg_epoch{epoch}_step{step}.png', img_array, cmap='gray')\n",
    "                print(noise.shape)\n",
    "                plt.imsave(f'results/noise_epoch{epoch}_step{step}.png',\n",
    "                           noise[0, 0].detach().cpu().numpy(), cmap='gray')\n",
    "\n",
    "            prediction = model(x=combined, timesteps=timesteps)\n",
    "            if epoch == 0:\n",
    "                plt.imsave(f'results/prediction_epoch{epoch}_step{step}.png',\n",
    "                           prediction[0, 0].detach().cpu().numpy(), cmap='gray')\n",
    "            loss = F.mse_loss(prediction.float(), noise.float())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "    logger.info(f\"Epoch: {epoch} Training loss: {epoch_loss / (step + 1)}\")\n",
    "\n",
    "    epoch_loss_list.append(epoch_loss / (step + 1))\n",
    "\n",
    "    if (epoch) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        for step, data_val in enumerate(val_loader):\n",
    "            images = data_val[\"image\"].to(device)\n",
    "            seg = data_val[\"label\"].to(device)\n",
    "            timesteps = torch.randint(0, n_timesteps, (len(images),)).to(device)\n",
    "            with torch.no_grad():\n",
    "                with autocast(enabled=True):\n",
    "                    noise = torch.randn_like(seg).to(device)\n",
    "                    noisy_seg = scheduler.add_noise(original_samples=seg, noise=noise, timesteps=timesteps)\n",
    "                    combined = torch.cat((images, noisy_seg), dim=1)\n",
    "                    prediction = model(x=combined, timesteps=timesteps)\n",
    "                    val_loss = F.mse_loss(prediction.float(), noise.float())\n",
    "            val_epoch_loss += val_loss.item()\n",
    "        logger.info(f\"Epoch: {epoch} Validation loss: {val_epoch_loss / (step + 1)}\")\n",
    "        val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
    "\n",
    "torch.save(model.state_dict(), \"./segmodel.pt\")\n",
    "total_time = time.time() - total_start\n",
    "minutes = total_time // 60\n",
    "seconds = total_time % 60\n",
    "\n",
    "logger.info(f\"train diffusion completed, total time: {int(minutes)}m {int(seconds)}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_epoch_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Learning Curves Diffusion Model\", fontsize=20)\n",
    "plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_loss_list, color=\"red\", linewidth=2.0, label=\"Train\")\n",
    "plt.plot(\n",
    "    np.linspace(val_interval, n_epochs, int(n_epochs / val_interval)),\n",
    "    val_epoch_loss_list,\n",
    "    color=\"green\",\n",
    "    linewidth=2.0,\n",
    "    label=\"Validation\",\n",
    ")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.show()\n",
    "plt.savefig(\"diffusion learning curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = val_ds[idx]\n",
    "inputimg = data[\"image\"]\n",
    "inputlabel = data[\"label\"]\n",
    "\n",
    "plt.figure(\"input\"+str(inputlabel))\n",
    "plt.imshow(inputimg.T, vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"input_image.png\")\n",
    "\n",
    "plt.figure(\"input\"+str(inputlabel))\n",
    "plt.imshow(inputlabel.T, vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"input_label.png\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "input_img = inputimg[None, ...].to(device)\n",
    "\n",
    "ensemble = []\n",
    "for k in range(5):\n",
    "    noise_shape = list(input_img.shape)\n",
    "    noise_shape[1] = 1\n",
    "    noise = torch.randn(noise_shape).to(device)\n",
    "    current_img = noise\n",
    "    combined = torch.cat((input_img, noise), dim=1)\n",
    "    scheduler.set_timesteps(num_inference_steps=n_timesteps)\n",
    "    progress_bar = tqdm(scheduler.timesteps)\n",
    "    chain = torch.zeros(current_img.shape)\n",
    "    for t in progress_bar:\n",
    "        with autocast(enabled=False):\n",
    "            with torch.no_grad():\n",
    "                model_output = model(combined, timesteps=torch.Tensor((t,)).to(current_img.device))\n",
    "                current_img, _ = scheduler.step(model_output, t, current_img)\n",
    "                if t % (n_timesteps//10) == 0:\n",
    "                    chain = torch.cat((chain, current_img.cpu()), dim=-1)\n",
    "                combined = torch.cat((input_img, current_img), dim=1)\n",
    "    plt.style.use(\"default\")\n",
    "    plt.imshow(chain[0, 0, ..., 512:].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.savefig(f\"sampling_{k}.png\")\n",
    "    ensemble.append(current_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(im1, im2, empty_score=1.0):\n",
    "    im1 = np.asarray(im1).astype(bool)\n",
    "    im2 = np.asarray(im2).astype(bool)\n",
    "\n",
    "    im_sum = im1.sum() + im2.sum()\n",
    "    if im_sum == 0:\n",
    "        return empty_score\n",
    "\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2.0 * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ensemble)):\n",
    "    prediction = torch.where(ensemble[i] > 0.5, 1, 0).float()\n",
    "    score = dice_coeff(prediction[0, 0].cpu(), inputlabel.cpu())\n",
    "    logger.info(f\"Dice score of sample{str(i)}: {score}\")\n",
    "\n",
    "E = torch.where(torch.cat(ensemble) > 0.5, 1, 0).float()\n",
    "var = torch.var(E, dim=0)\n",
    "mean = torch.mean(E, dim=0)\n",
    "mean_prediction = torch.where(mean > 0.5, 1, 0).float()\n",
    "\n",
    "score = dice_coeff(mean_prediction[0, ...].cpu(), inputlabel.cpu())\n",
    "logger.info(f\"Dice score on the mean map: {score}\")\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(mean[0, ...].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.savefig(\"mean.png\")\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(var[0, ...].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.savefig(\"variance.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
